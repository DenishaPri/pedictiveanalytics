# -*- coding: utf-8 -*-
"""LVADSUSR81_DENISHAPRIYAG_LAB2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IiOKxXlssdvif8ogQavaAbsNLjfJ8keT
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing

df = pd.read_csv('/content/drive/MyDrive/auto-mpg.csv')
df.columns.tolist()

df.info()

df.describe()

df.isnull().sum()

df = df.fillna(df.mean())
# df.dropna()

df.isnull().sum()

df.duplicated().sum()

numerical_columns = df.columns[df.dtypes != "object"]
numerical_columns

# before removing outliers
for i in numerical_columns:
  plt.figure(figsize = (10,6))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

# remove outliers
def detect_and_treat_outliers(df,columns):

  for col in columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    median = df[col].median()
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median, df[col])

  return df

df = detect_and_treat_outliers(df,numerical_columns)
numerical_columns = df.columns[df.dtypes != "object"]

# after removing outliers
for i in numerical_columns:
  plt.figure(figsize = (10,6))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

categorical_columns = df.columns[df.dtypes == "object"]
categorical_columns

for i in categorical_columns:
  plt.figure(figsize = (5,5))
  sns.scatterplot(data=df[i])
  plt.title(i)
  plt.show()

#-----------encoder-----------------
label_encoder = preprocessing.LabelEncoder()
df['horsepower'] = label_encoder.fit_transform(df['horsepower'])
df.head()

#--------feature selection-------------
x = df[['cylinders','displacement','horsepower','weight','acceleration']]
y = df['mpg']

#----------splitting----------
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2,random_state=42)

#-------model selection--------
clf = DecisionTreeRegressor(random_state = 42)
clf.fit(x_train, y_train)
y_pred = clf.predict(x_test)

print('prediction')
print(y_pred)
print('actual')
print(y_test)

# ---------Calculate evaluation metrics-----------

r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test,y_pred))

print("R-squared:", r2)
print("Root Mean Squared Error (RMSE):", rmse)